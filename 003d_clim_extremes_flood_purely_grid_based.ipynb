{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from itertools import product\n",
    "from datetime import datetime, timedelta\n",
    "import argparse\n",
    "import logging\n",
    "from scipy.special import gamma, factorial #gamma function\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes #put inset plot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dir folder path\n",
    "dir_in = '/g/data/er4/zk6340/Hydro_projection/data_flood_scenario_qtot'\n",
    "dir_out = '/g/data/er4/zk6340/code/Script_Hydro-projections'\n",
    "\n",
    "# parameter\n",
    "parameter = 'qtot'\n",
    "\n",
    "# Which cluster\n",
    "clusters = {'CS':1,'EC':2,'MB':4,'MN':5,'R':6,'SS':7,'SSWF':8,'WT':9}\n",
    "which_cluster = clusters['MB']\n",
    "\n",
    "# return period\n",
    "yT = 20\n",
    "\n",
    "# historical period\n",
    "hist_st = '19760101'\n",
    "hist_end = '20051231'\n",
    "\n",
    "# projection period\n",
    "yr_st = '20160101'\n",
    "yr_end = '20451231'\n",
    "\n",
    "# Participating GCMs, Bias correction approaches, Emission scenarios\n",
    "gcms = ['CNRM-CERFACS-CNRM-CM5','CSIRO-BOM-ACCESS1-0','MIROC-MIROC5','NOAA-GFDL-GFDL-ESM2M']\n",
    "bias_corr = ['CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP','r240x120-ISIMIP2b-AWAP', 'r240x120-MRNBC-AWAP', 'r240x120-QME-AWAP']\n",
    "emission = ['rcp45','rcp85']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get to the historical/scenario file\n",
    "def get_file(parameter,which_gcm,which_emission,which_bias_corr, which_metric, yr_end, yr_st):\n",
    "    base_filename = '%s_AUS-5_%s_%s_r1i1p1_%s_%s_%s-%s.nc'%(parameter,which_gcm,which_emission,which_bias_corr,which_metric,yr_end,yr_st)\n",
    "    return(base_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get percentage change for 'Mean' and 'Max'\n",
    "def percentage_change(parameter, gcm, scenario, bias_correction, statistics, hist_end, hist_st, yr_end, yr_st):\n",
    "    # Historical period\n",
    "    filename_hist = get_file(parameter, gcm,'historical', bias_correction, statistics, hist_end, hist_st)\n",
    "    ds_hist = xr.open_dataset(os.path.join(dir_in,filename_hist)) \n",
    "    ds_hist_cluster = ds_hist[parameter].where(mask == which_cluster)\n",
    "    ds_hist_cluster_spatial_mean = ds_hist_cluster.NRM_cluster.mean().item(0)\n",
    "    # Future scenario\n",
    "    filename_scenario = get_file(parameter, gcm, scenario, bias_correction, statistics,yr_end,yr_st)\n",
    "    ds_scenario = xr.open_dataset(os.path.join(dir_in,filename_scenario)) \n",
    "    ds_scenario_cluster = ds_scenario[parameter].where(mask == which_cluster)\n",
    "    ds_scenario_cluster_spatial_mean = ds_scenario_cluster.NRM_cluster.mean().item(0)   \n",
    "    percent_change = ((ds_scenario_cluster_spatial_mean-ds_hist_cluster_spatial_mean)*100)/ds_hist_cluster_spatial_mean  \n",
    "    return(percent_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the L/LH moments: \n",
    "# Note: L-moments when h = 0 \n",
    "def lh(x, h):\n",
    "    lh1 = 0\n",
    "    lh2 = 0\n",
    "    lh3 = 0\n",
    "    lh4 = 0\n",
    "    ts = np.sort(x)\n",
    "    n = len(ts)\n",
    "    for i in range (0, len(ts)): \n",
    "        cl0 = 1\n",
    "        if h>0:\n",
    "            for j in range (0, h): \n",
    "                cl0 = cl0*(i-j)/(j+1)\n",
    "        cl1 = cl0*(i+1-h-1)/(h+1)\n",
    "        cl2 = cl1*(i+1-h-2)/(h+2)\n",
    "        cl3 = cl2*(i+1-h-3)/(h+3)\n",
    "        cr1 = n-(i+1)\n",
    "        cr2 = cr1*(n-(i+1)-1)/2\n",
    "        cr3 = cr2*(n-(i+1)-2)/3\n",
    "        lh1 = lh1+cl0* ts[i]\n",
    "        lh2 = lh2+(cl1-cl0*cr1)* ts[i]\n",
    "        lh3 = lh3+(cl2-2*cl1*cr1+cl0*cr2)* ts[i]\n",
    "        lh4 = lh4+(cl3-3*cl2*cr1+3*cl1*cr2-cl0*cr3)* ts[i] \n",
    "    c0 = 1\n",
    "    if h>0:\n",
    "        for j in range (0, h): \n",
    "            c0 = c0*(n+1-(j+1))/(j+1)\n",
    "    c1 = c0*(n+1-h-1)/(h+1)\n",
    "    c2 = c1*(n+1-h-2)/(h+2)\n",
    "    c3 = c2*(n+1-h-3)/(h+3)\n",
    "    c4 = c3*(n+1-h-4)/(h+4)\n",
    "    lh1 = lh1/c1\n",
    "    lh2 = lh2/c2/2\n",
    "    lh3 = lh3/c3/3\n",
    "    lh4 = lh4/c4/4\n",
    "    return(lh1,lh2,lh3,lh4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate return period: GEV distribution\n",
    "def gev_return_period(data, T):\n",
    "    lamda1= lh(data, 0)[0]\n",
    "    lamda2= lh(data, 0)[1]\n",
    "    lamda3= lh(data, 0)[2]\n",
    "    lamda4= lh(data, 0)[3]\n",
    "    c=(2*lamda2/(lamda3+3*lamda2))-(np.log(2)/np.log(3))\n",
    "    k=7.859*c+2.9554*c**2\n",
    "    alpha=k*lamda2/(gamma(1+k)*(1-2**(-k)))\n",
    "    zeta=lamda1-alpha/k*(1-(gamma(1+k)))\n",
    "    qt=zeta+(alpha/k)*(1-(-np.log(1-1/T))**k)\n",
    "    return(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate return period: LP3 distribution\n",
    "def lp3_return_period(data, T):\n",
    "    xbar=np.mean(data)\n",
    "    stdev=np.std(data)\n",
    "    xskew=skew(data)\n",
    "    zp=norm.ppf(1-1/T)\n",
    "    ff=(2/xskew)*((1+(zp*xskew)/6-xskew**2/36)**3)-2/xskew\n",
    "    qt=xbar+stdev*ff\n",
    "    return(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get annual maximum timeseries for a grid cell\n",
    "def ts_data(dataset, lat, lon, parameter):\n",
    "    ds = dataset.sel(lat = lat, lon = lon, method = 'nearest')[parameter].values\n",
    "    return(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cluster mask\n",
    "mask = xr.open_dataset(os.path.join(dir_in,'NRM_clusters.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking up grid cells for a particular cluster\n",
    "grid_cells = mask.where(mask == which_cluster).NRM_cluster.to_dataframe().reset_index()\n",
    "grid_cells = grid_cells.dropna(axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [(i, k, x) for i, k, x in product(gcms,emission, bias_corr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CNRM-CERFACS-CNRM-CM5', 'rcp45', 'CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP'),\n",
       " ('CNRM-CERFACS-CNRM-CM5', 'rcp45', 'r240x120-ISIMIP2b-AWAP'),\n",
       " ('CNRM-CERFACS-CNRM-CM5', 'rcp45', 'r240x120-MRNBC-AWAP'),\n",
       " ('CNRM-CERFACS-CNRM-CM5', 'rcp45', 'r240x120-QME-AWAP'),\n",
       " ('CNRM-CERFACS-CNRM-CM5', 'rcp85', 'CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP'),\n",
       " ('CNRM-CERFACS-CNRM-CM5', 'rcp85', 'r240x120-ISIMIP2b-AWAP'),\n",
       " ('CNRM-CERFACS-CNRM-CM5', 'rcp85', 'r240x120-MRNBC-AWAP'),\n",
       " ('CNRM-CERFACS-CNRM-CM5', 'rcp85', 'r240x120-QME-AWAP'),\n",
       " ('CSIRO-BOM-ACCESS1-0', 'rcp45', 'CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP'),\n",
       " ('CSIRO-BOM-ACCESS1-0', 'rcp45', 'r240x120-ISIMIP2b-AWAP'),\n",
       " ('CSIRO-BOM-ACCESS1-0', 'rcp45', 'r240x120-MRNBC-AWAP'),\n",
       " ('CSIRO-BOM-ACCESS1-0', 'rcp45', 'r240x120-QME-AWAP'),\n",
       " ('CSIRO-BOM-ACCESS1-0', 'rcp85', 'CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP'),\n",
       " ('CSIRO-BOM-ACCESS1-0', 'rcp85', 'r240x120-ISIMIP2b-AWAP'),\n",
       " ('CSIRO-BOM-ACCESS1-0', 'rcp85', 'r240x120-MRNBC-AWAP'),\n",
       " ('CSIRO-BOM-ACCESS1-0', 'rcp85', 'r240x120-QME-AWAP'),\n",
       " ('MIROC-MIROC5', 'rcp45', 'CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP'),\n",
       " ('MIROC-MIROC5', 'rcp45', 'r240x120-ISIMIP2b-AWAP'),\n",
       " ('MIROC-MIROC5', 'rcp45', 'r240x120-MRNBC-AWAP'),\n",
       " ('MIROC-MIROC5', 'rcp45', 'r240x120-QME-AWAP'),\n",
       " ('MIROC-MIROC5', 'rcp85', 'CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP'),\n",
       " ('MIROC-MIROC5', 'rcp85', 'r240x120-ISIMIP2b-AWAP'),\n",
       " ('MIROC-MIROC5', 'rcp85', 'r240x120-MRNBC-AWAP'),\n",
       " ('MIROC-MIROC5', 'rcp85', 'r240x120-QME-AWAP'),\n",
       " ('NOAA-GFDL-GFDL-ESM2M', 'rcp45', 'CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP'),\n",
       " ('NOAA-GFDL-GFDL-ESM2M', 'rcp45', 'r240x120-ISIMIP2b-AWAP'),\n",
       " ('NOAA-GFDL-GFDL-ESM2M', 'rcp45', 'r240x120-MRNBC-AWAP'),\n",
       " ('NOAA-GFDL-GFDL-ESM2M', 'rcp45', 'r240x120-QME-AWAP'),\n",
       " ('NOAA-GFDL-GFDL-ESM2M', 'rcp85', 'CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP'),\n",
       " ('NOAA-GFDL-GFDL-ESM2M', 'rcp85', 'r240x120-ISIMIP2b-AWAP'),\n",
       " ('NOAA-GFDL-GFDL-ESM2M', 'rcp85', 'r240x120-MRNBC-AWAP'),\n",
       " ('NOAA-GFDL-GFDL-ESM2M', 'rcp85', 'r240x120-QME-AWAP')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_daily_mean = percentage_change(parameter, values[27][0], values[27][1], values[27][2], 'Mean', hist_end, hist_st, yr_end, yr_st)\n",
    "\n",
    "#Change in max\n",
    "change_daily_max = percentage_change(parameter, values[27][0], values[27][1], values[27][2], 'Max', hist_end, hist_st, yr_end, yr_st)  \n",
    "\n",
    "#Change in return period\n",
    "# Annual Max - for historical period\n",
    "filename_hist_annual_max = get_file(parameter,values[27][0],'historical',values[27][2],'Annual_Max',hist_end,hist_st)\n",
    "ds_hist_annual_max = xr.open_dataset(os.path.join(dir_in,filename_hist_annual_max))\n",
    "# Annual Max - for scenario period\n",
    "filename_scenario_annual_max = get_file(parameter,values[27][0],values[27][1],values[27][2],'Annual_Max',yr_end,yr_st)\n",
    "ds_scenario_annual_max = xr.open_dataset(os.path.join(dir_in,filename_scenario_annual_max))  \n",
    "# calculate retrun period for the historical period\n",
    "all_yT = []\n",
    "for i in range (0, len(grid_cells)): \n",
    "    hist_yT_point = gev_return_period(ts_data(ds_hist_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)\n",
    "    scenario_yT_point = gev_return_period(ts_data(ds_scenario_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)       \n",
    "    yT_point = {'lat':grid_cells.lat[i],'lon':grid_cells.lon[i],'hist_yT':hist_yT_point,'future_yT':scenario_yT_point}\n",
    "    all_yT.append(yT_point)\n",
    "all_return_period = pd.DataFrame(all_yT)   \n",
    "change_return_period = ((all_return_period['future_yT'].mean()-all_return_period['hist_yT'].mean())*100)/all_return_period['hist_yT'].mean()   \n",
    "dd = {'GCM':values[27][0],'Bias Correction':values[27][2],'Emission':values[27][1],'Change in Daily Mean':change_daily_mean,'Change in daily Max':change_daily_max, 'Change in Return Period':change_return_period}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GCM': 'NOAA-GFDL-GFDL-ESM2M',\n",
       " 'Bias Correction': 'r240x120-QME-AWAP',\n",
       " 'Emission': 'rcp45',\n",
       " 'Change in Daily Mean': -36.33033420702664,\n",
       " 'Change in daily Max': -6.194419040153765,\n",
       " 'Change in Return Period': -21.326724585821314}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = ds_hist_annual_max.sel(lat = -32.25, lon = 145.65, method = 'nearest')[parameter].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047323745597340656"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_return_period.hist_yT.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04000392565388619"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_return_period.future_yT.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29848486,  0.09815075,  0.10894123,  0.17728981,  0.07993447,\n",
       "        0.05687778,  0.03262357,  0.08426319,  0.11417754,  2.83034754,\n",
       "        0.31669611,  0.97379208,  0.3431657 ,  0.43425098,  0.3285206 ,\n",
       "        0.15549701,  0.3161217 ,  0.22977819,  0.2376546 ,  2.58493233,\n",
       "        0.86850059,  0.32189187, 12.81156254,  0.61593449,  0.54709554,\n",
       "        0.27335545,  0.28320321,  0.30237091,  0.3749817 ,  0.27856681])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2278063781658157"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gev_return_period(data_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plot\n",
    "for grd in range(0,len(all_return_period)):\n",
    "            fig = plt.figure()\n",
    "            fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "            map = Basemap(110.,-45.,155,-10.5, \n",
    "                       lat_0=24.75, lon_0=134.0, lat_1=-10, lat_2=-40,\n",
    "                        rsphere=(6378137.00,6356752.3142),\n",
    "                        projection='cyl')\n",
    "            map.drawcoastlines()\n",
    "            map.drawstates()\n",
    "            map.drawlsmask(land_color='Linen', ocean_color='white')\n",
    "            map.drawcountries()\n",
    "            map.drawparallels(np.arange(-43,-10,10),labels=[1,0,0,0])\n",
    "            map.drawmeridians(np.arange(110,155,10),labels=[0,0,0,1])\n",
    "            if all_return_period.hist_yT[grd]>0:\n",
    "                plt.scatter(all_return_period.lon[grd],all_return_period.lat[grd], marker = '.', color = 'red')\n",
    "            else:\n",
    "                plt.scatter(all_return_period.lon[grd],all_return_period.lat[grd], marker = '.', color = 'green')\n",
    "            output_file = 'Cluster: MB_historical_return_period.jpeg'\n",
    "            plt.savefig(os.path.join(dir_out,output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plot\n",
    "for grd in range(0,len(all_return_period)):\n",
    "            fig = plt.figure()\n",
    "            fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "            map = Basemap(110.,-45.,155,-10.5, \n",
    "                       lat_0=24.75, lon_0=134.0, lat_1=-10, lat_2=-40,\n",
    "                        rsphere=(6378137.00,6356752.3142),\n",
    "                        projection='cyl')\n",
    "            map.drawcoastlines()\n",
    "            map.drawstates()\n",
    "            map.drawlsmask(land_color='Linen', ocean_color='white')\n",
    "            map.drawcountries()\n",
    "            map.drawparallels(np.arange(-43,-10,10),labels=[1,0,0,0])\n",
    "            map.drawmeridians(np.arange(110,155,10),labels=[0,0,0,1])\n",
    "            if all_return_period.future_yT[grd]>0:\n",
    "                plt.scatter(all_return_period.lon[grd],all_return_period.lat[grd], marker = '.', color = 'red')\n",
    "            else:\n",
    "                plt.scatter(all_return_period.lon[grd],all_return_period.lat[grd], marker = '.', color = 'green')\n",
    "            output_file = 'Cluster: MB_future_return_period.jpeg'\n",
    "            plt.savefig(os.path.join(dir_out,output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caluster_flood_indicator=[]\n",
    "for val in enumerate(values):   \n",
    "#for val in enumerate(values[0]):  \n",
    "    #Change in mean\n",
    "    change_daily_mean = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Mean', hist_end, hist_st, yr_end, yr_st)\n",
    "\n",
    "    #Change in max\n",
    "    change_daily_max = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Max', hist_end, hist_st, yr_end, yr_st)  \n",
    "    \n",
    "    #Change in return period\n",
    "    # Annual Max - for historical period\n",
    "    filename_hist_annual_max = get_file(parameter,val[1][0],'historical',val[1][2],'Annual_Max',hist_end,hist_st)\n",
    "    ds_hist_annual_max = xr.open_dataset(os.path.join(dir_in,filename_hist_annual_max))\n",
    "    # Annual Max - for scenario period\n",
    "    filename_scenario_annual_max = get_file(parameter,val[1][0],val[1][1],val[1][2],'Annual_Max',yr_end,yr_st)\n",
    "    ds_scenario_annual_max = xr.open_dataset(os.path.join(dir_in,filename_scenario_annual_max))  \n",
    "    # calculate retrun period for the historical period\n",
    "    all_yT = []\n",
    "    for i in range (0, len(grid_cells)): \n",
    "        hist_yT_point = gev_return_period(ts_data(ds_hist_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)\n",
    "        scenario_yT_point = gev_return_period(ts_data(ds_scenario_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)       \n",
    "        yT_point = {'hist_yT':hist_yT_point,'future_yT':scenario_yT_point}\n",
    "        all_yT.append(yT_point)\n",
    "    all_return_period = pd.DataFrame(all_yT)   \n",
    "    change_return_period = ((all_return_period['future_yT'].mean()-all_return_period['hist_yT'].mean())*100)/all_return_period['hist_yT'].mean()   \n",
    "    dd = {'GCM':val[1][0],'Bias Correction':val[1][2],'Emission':val[1][1],'Change in Daily Mean':change_daily_mean,'Change in daily Max':change_daily_max, 'Change in Return Period':change_return_period}\n",
    "    cluster_flood_indicator.append(dd)\n",
    "    break # just want to check one loop/one ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flood_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values[10][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flood_indicator=[]\n",
    "for val in enumerate(values):   \n",
    "#for val in enumerate(values[0]):  \n",
    "    #Change in mean\n",
    "    change_daily_mean = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Mean', hist_end, hist_st, yr_end, yr_st)\n",
    "\n",
    "    #Change in max\n",
    "    change_daily_max = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Max', hist_end, hist_st, yr_end, yr_st)  \n",
    "    \n",
    "    #Change in return period\n",
    "    # Annual Max - for historical period\n",
    "    filename_hist_annual_max = get_file(parameter,val[1][0],'historical',val[1][2],'Annual_Max',hist_end,hist_st)\n",
    "    ds_hist_annual_max = xr.open_dataset(os.path.join(dir_in,filename_hist_annual_max))\n",
    "    # calculate retrun period for the historical period\n",
    "    hist_yT = []\n",
    "    for i in range (0, len(grid_cells)): \n",
    "        hist_yT_point = gev_return_period(ts_data(ds_hist_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)\n",
    "        hist_yT.append(hist_yT_point)\n",
    "    hist_yT_mean = pd.DataFrame(hist_yT).mean()[0]\n",
    "    # Annual Max - for scenario period\n",
    "    filename_scenario_annual_max = get_file(parameter,val[1][0],val[1][1],val[1][2],'Annual_Max',yr_end,yr_st)\n",
    "    ds_scenario_annual_max = xr.open_dataset(os.path.join(dir_in,filename_scenario_annual_max))\n",
    "    # calculate retrun period for the scenario period\n",
    "    scenario_yT = []\n",
    "    for j in range (0, len(grid_cells)): \n",
    "        scenario_yT_point = gev_return_period(ts_data(ds_scenario_annual_max, grid_cells.lat[j], grid_cells.lon[j], parameter), yT)\n",
    "        scenario_yT.append(scenario_yT_point)\n",
    "    scenario_yT_mean = pd.DataFrame(scenario_yT).mean()[0]\n",
    "    change_return_period = ((scenario_yT_mean-hist_yT_mean)*100)/hist_yT_mean\n",
    "    \n",
    "    dd = {'GCM':val[1][0],'Bias Correction':val[1][2],'Emission':val[1][1],'Change in Daily Mean':change_daily_mean,'Change in daily Max':change_daily_max, 'Change in Return Period':change_return_period}\n",
    "    cluster_flood_indicator.append(dd)\n",
    "    break # just want to check one loop/one ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flood_indicator=[]\n",
    "for val in enumerate(values):   \n",
    "#for val in enumerate(values[0]):  \n",
    "    #Change in mean\n",
    "    change_daily_mean = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Mean', hist_end, hist_st, yr_end, yr_st)\n",
    "\n",
    "    #Change in max\n",
    "    change_daily_max = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Max', hist_end, hist_st, yr_end, yr_st)  \n",
    "    \n",
    "    #Change in return period\n",
    "    # Annual Max - for historical period\n",
    "    filename_hist_annual_max = get_file(parameter,val[1][0],'historical',val[1][2],'Annual_Max',hist_end,hist_st)\n",
    "    ds_hist_annual_max = xr.open_dataset(os.path.join(dir_in,filename_hist_annual_max))\n",
    "    # Annual Max - for scenario period\n",
    "    filename_scenario_annual_max = get_file(parameter,val[1][0],val[1][1],val[1][2],'Annual_Max',yr_end,yr_st)\n",
    "    ds_scenario_annual_max = xr.open_dataset(os.path.join(dir_in,filename_scenario_annual_max))  \n",
    "    # calculate retrun period for the historical period\n",
    "    change_yT = []\n",
    "    for i in range (0, len(grid_cells)): \n",
    "        hist_yT_point = gev_return_period(ts_data(ds_hist_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)\n",
    "        scenario_yT_point = gev_return_period(ts_data(ds_scenario_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)\n",
    "        diff_yT = ((scenario_yT_point-hist_yT_point)*100)/hist_yT_point\n",
    "        change_yT.append(diff_yT)\n",
    "    change_return_period = pd.DataFrame(change_yT).mean()[0]   \n",
    "    dd = {'GCM':val[1][0],'Bias Correction':val[1][2],'Emission':val[1][1],'Change in Daily Mean':change_daily_mean,'Change in daily Max':change_daily_max, 'Change in Return Period':change_return_period}\n",
    "    cluster_flood_indicator.append(dd)\n",
    "    break # just want to check one loop/one ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flood_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
