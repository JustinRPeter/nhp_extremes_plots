{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awrams.utils.processing.extract import extract\n",
    "from awrams.utils.gis import ShapefileDB,extent_from_record\n",
    "from awrams.utils.extents import get_default_extent\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import product\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable name, catchment\n",
    "var_name='rain_day' # 'qtot'/'rain_day'\n",
    "# Which catchment\n",
    "#selected_catchments = ['Burdekin']\n",
    "selected_catchments = ['Central_West_River_Catchment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return period\n",
    "yT = 20\n",
    "\n",
    "# Future period\n",
    "#future_period = {'scn1':['2016-01-01 12:00:00','2045-12-31 00:00:00'],'scn2':['2036-01-01 12:00:00','2065-12-31 00:00:00'],'scn3':['2056-01-01 12:00:00','2085-12-31 00:00:00'],'scn4':['2069-12-31 12:00:00','2099-12-31 00:00:00']}\n",
    "future_period = {'scn1':['2016-01-01 12:00:00','2045-12-31 00:00:00','2030'],'scn3':['2056-01-01 12:00:00','2085-12-31 00:00:00','2070']}\n",
    "\n",
    "# historical period\n",
    "period_hist = pd.date_range('1 jan 1976', '31 dec 2005', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to historical data\n",
    "if var_name == 'qtot':\n",
    "    data_hist = '/g/data/er4/exv563/hydro_projections/data/drought_2018_analysis/awra_v6_static_winds/daily'\n",
    "else:\n",
    "    data_hist = '/g/data/er4/data/CLIMATE/rain_day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dir\n",
    "output_dir='/g/data/er4/zk6340/Hydro_projection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participating GCMs, Bias correction approaches, Emission scenarios\n",
    "gcms = ['CNRM-CERFACS-CNRM-CM5','CSIRO-BOM-ACCESS1-0','MIROC-MIROC5','NOAA-GFDL-GFDL-ESM2M']\n",
    "bias_corr = ['CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP','r240x120-ISIMIP2b-AWAP', 'r240x120-MRNBC-AWAP', 'r240x120-QME-AWAP']\n",
    "emission = ['rcp45','rcp85']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set the customer folder and shapefile name\n",
    "shp_name = 'Central_West_River_Catchment'\n",
    "## Data Request dir folder path\n",
    "DataRequest_dir = '/g/data/er4/zk6340/Hydro_projection/%s/'%(shp_name)\n",
    "## Read shape file\n",
    "shp = DataRequest_dir + shp_name + '.shp'\n",
    "sdb = ShapefileDB(shp)\n",
    "sdf = sdb.get_records_df()\n",
    "emap = pickle.load(open(DataRequest_dir + shp_name + '.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get to the path \n",
    "def get_path(parameter,which_gcm,which_emission,which_bias_corr):\n",
    "    if parameter == 'qtot':\n",
    "        path = os.path.join('/g/data/wj02/COMPLIANT/HMOUTPUT/output/AUS-5/BoM/AWRALv6-1-%s/%s/r1i1p1/%s/latest/day/%s'%(which_gcm,which_emission,which_bias_corr,parameter))\n",
    "    else:\n",
    "        path = os.path.join('/g/data/wj02/COMPLIANT/HMINPUT/output/AUS-5/BoM/%s/%s/r1i1p1/%s/latest/day/%s'%(which_gcm,which_emission,which_bias_corr,parameter))\n",
    "    return(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get to the file\n",
    "def get_file(which_gcm,which_bias_corr,which_emission,parameter):\n",
    "    if parameter == 'qtot':\n",
    "        base_filename = 'AWRALv6-1-%s_%s_%s_r1i1p1_%s_AUS-5_day_v1_20060101-20991231.nc'%(which_gcm,which_bias_corr,which_emission,parameter)\n",
    "    else:\n",
    "        base_filename = '%s_AUS-5_%s_%s_r1i1p1_%s_v1_day_20060101-20991231.nc'%(parameter,which_gcm,which_emission,which_bias_corr)       \n",
    "    return(base_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenarios\n",
    "values = [(i, j) for i, j in product(selected_catchments,future_period)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in future scenario netcdf file, variable 'rain_day' is changed to 'pr'\n",
    "if var_name == 'rain_day':\n",
    "    variable = 'pr'\n",
    "else: \n",
    "    variable = 'qtot'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all the emsemble identities\n",
    "ensb_mem = [(k, l, m) for k, l, m in product(gcms,emission, bias_corr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central_West_River_Catchment\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9d17b211bd99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#Annual max for historical data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_hist\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/%s*.nc'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mds_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatchment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdata_mean_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich_catchment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdata_max_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich_catchment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/er4/AWRACMS/awrams_cm_v6.1/utils/awrams/utils/processing/extract.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(path, pattern, var_name, extent_map, period)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSplitFileManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_existing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mextract_from_filemanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextent_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_from_filemanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextent_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/er4/AWRACMS/awrams_cm_v6.1/utils/awrams/utils/processing/extract.py\u001b[0m in \u001b[0;36mextract_from_filemanager\u001b[0;34m(sfm, extent_map, period)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mawrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAX_EXTRACT_CHUNK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmax_spatial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextent_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mdsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapped_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Get the calculation done!\n",
    "ensb_together = []\n",
    "for ensb in enumerate(ensb_mem):\n",
    "    ds_produced = []\n",
    "    for val in enumerate(values): \n",
    "        which_catchment = val[1][0]\n",
    "        print(which_catchment)\n",
    "        period_projected = pd.date_range(future_period[val[1][1]][0], future_period[val[1][1]][1], freq='D')\n",
    "        catchment = {}\n",
    "        for key in emap:\n",
    "            if which_catchment in key:\n",
    "                catchment[key] = emap[key]\n",
    "        #Annual max for historical data                \n",
    "        pattern = data_hist + '/%s*.nc' % var_name\n",
    "        ds_hist = extract(data_hist, pattern, var_name, catchment, period_hist)\n",
    "        data_mean_hist = ds_hist[which_catchment].values.mean()\n",
    "        data_max_hist = ds_hist[which_catchment].values.max()\n",
    "        data_annual_max_hist = ds_hist.resample(rule='A-DEC').max()\n",
    "        \n",
    "        #Annual max for future data    \n",
    "        input_path_gcm = get_path(variable,ensb[1][0],ensb[1][1],ensb[1][2])\n",
    "        input_file = get_file(ensb[1][0],ensb[1][2],ensb[1][1],variable) \n",
    "        pattern_gcm = input_path_gcm + '/' + input_file\n",
    "        ds_gcm = extract(input_path_gcm, pattern_gcm, variable, catchment, period_projected)\n",
    "        if var_name == 'rain_day':\n",
    "            ds_convrt = ds_gcm*86400\n",
    "        else:\n",
    "            ds_convrt = ds_gcm\n",
    "        data_mean_future = ds_convrt[which_catchment].values.mean()\n",
    "        data_max_future = ds_convrt[which_catchment].values.max()\n",
    "        data_annual_max_future = ds_convrt.resample(rule='A-DEC').max()\n",
    "        #Calculate 20 year return period\n",
    "#         hist_yT = gev_return_period(np.sort(data_annual_max_hist[which_catchment].values), yT)\n",
    "#         future_yT = gev_return_period(np.sort(data_annual_max_future[which_catchment].values), yT)\n",
    "#         dd = {'Catchment': which_catchment,'Mean over historical period':data_mean_hist,'Mean over future period':data_mean_future,'Max over historical period':data_max_hist,'Max over future period':data_max_future,'20-yr yT over historical period':hist_yT,'20-yr yT over future period':future_yT,'Future period':future_period[val[1][1]][0],'Scenario':future_period[val[1][1]][2],'GCM':ensb[1][0],'Emission':ensb[1][1],'Bias Correction':ensb[1][2]}\n",
    "#         print (dd)\n",
    "#         ds_produced.append(dd)\n",
    "        break\n",
    "    break\n",
    "    #ensb_together.append(pd.DataFrame(ds_produced)) # Appending pandas dataframes generated in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Central West River Catchment': origin: -29.95,143.95, shape: (102, 129), cell_size: 0.05}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_convrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gcm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
