{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from itertools import product\n",
    "from datetime import datetime, timedelta\n",
    "import argparse\n",
    "import logging\n",
    "from scipy.special import gamma, factorial #gamma function\n",
    "sys.path.append('/g/data/er4/zk6340/code/lmoments3')\n",
    "import lmoments3 as lm #calculate l-moments\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dir folder path\n",
    "dir_in = '/g/data/er4/zk6340/Hydro_projection/data_flood_scenario_pr'\n",
    "dir_out = '/g/data/er4/zk6340/code/Script_Hydro-projections'\n",
    "\n",
    "# parameter\n",
    "parameter = 'pr'\n",
    "\n",
    "# Which cluster\n",
    "clusters = {'CS':1,'EC':2,'MB':4,'MN':5,'R':6,'SS':7,'SSWF':8,'WT':9}\n",
    "which_cluster = clusters['MB']\n",
    "\n",
    "# return period\n",
    "yT = 20\n",
    "\n",
    "# historical period\n",
    "hist_st = '19760101'\n",
    "hist_end = '20051231'\n",
    "\n",
    "# projection period\n",
    "yr_st = '20160101'\n",
    "yr_end = '20451231'\n",
    "\n",
    "# Participating GCMs, Bias correction approaches, Emission scenarios\n",
    "gcms = ['CNRM-CERFACS-CNRM-CM5','CSIRO-BOM-ACCESS1-0','MIROC-MIROC5','NOAA-GFDL-GFDL-ESM2M']\n",
    "bias_corr = ['CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP','r240x120-ISIMIP2b-AWAP', 'r240x120-MRNBC-AWAP', 'r240x120-QME-AWAP']\n",
    "emission = ['rcp45','rcp85']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get to the historical/scenario file\n",
    "def get_file(parameter,which_gcm,which_emission,which_bias_corr, which_metric, yr_end, yr_st):\n",
    "    base_filename = '%s_AUS-5_%s_%s_r1i1p1_%s_%s_%s-%s.nc'%(parameter,which_gcm,which_emission,which_bias_corr,which_metric,yr_end,yr_st)\n",
    "    return(base_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get percentage change for 'Mean' and 'Max'\n",
    "def percentage_change(parameter, gcm, scenario, bias_correction, statistics, hist_end, hist_st, yr_end, yr_st):\n",
    "    # Historical period\n",
    "    filename_hist = get_file(parameter, gcm,'historical', bias_correction, statistics, hist_end, hist_st)\n",
    "    ds_hist = xr.open_dataset(os.path.join(dir_in,filename_hist)) \n",
    "    ds_hist_cluster = ds_hist[parameter].where(mask == which_cluster)\n",
    "    ds_hist_cluster_spatial_mean = ds_hist_cluster.NRM_cluster.mean().item(0)\n",
    "    # Future scenario\n",
    "    filename_scenario = get_file(parameter, gcm, scenario, bias_correction, statistics,yr_end,yr_st)\n",
    "    ds_scenario = xr.open_dataset(os.path.join(dir_in,filename_scenario)) \n",
    "    ds_scenario_cluster = ds_scenario[parameter].where(mask == which_cluster)\n",
    "    ds_scenario_cluster_spatial_mean = ds_scenario_cluster.NRM_cluster.mean().item(0)   \n",
    "    percent_change = ((ds_scenario_cluster_spatial_mean-ds_hist_cluster_spatial_mean)*100)/ds_hist_cluster_spatial_mean  \n",
    "    return(percent_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate return period: GEV distribution\n",
    "def gev_return_period(data, T):\n",
    "    lamda1= lm.lmom_ratios(data, nmom=4)[0]\n",
    "    lamda2= lm.lmom_ratios(data, nmom=4)[1]\n",
    "    lamda3= lm.lmom_ratios(data, nmom=4)[2]\n",
    "    lamda4= lm.lmom_ratios(data, nmom=4)[3]\n",
    "    c=(2*lamda2/(lamda3+3*lamda2))-(np.log(2)/np.log(3))\n",
    "    k=7.859*c+2.9554*c**2\n",
    "    alpha=k*lamda2/(gamma(1+k)*(1-2**(-k)))\n",
    "    zeta=lamda1-alpha/k*(1-(gamma(1+k)))\n",
    "    qt=zeta+(alpha/k)*(1-(-np.log(1-1/T))**k)\n",
    "    return(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get annual maximum timeseries for a grid cell\n",
    "def ts_data(dataset, lat, lon, parameter):\n",
    "    ds = dataset.sel(lat = lat, lon = lon, method = 'nearest')[parameter].values\n",
    "    return(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cluster mask\n",
    "mask = xr.open_dataset(os.path.join(dir_in,'NRM_clusters.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking up grid cells for a particular cluster\n",
    "grid_cells = mask.where(mask == which_cluster).NRM_cluster.to_dataframe().reset_index()\n",
    "grid_cells = grid_cells.dropna(axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [(i, k, x) for i, k, x in product(gcms,emission, bias_corr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_daily_mean = percentage_change(parameter, values[27][0], values[27][1], values[27][2], 'Mean', hist_end, hist_st, yr_end, yr_st)\n",
    "\n",
    "#Change in max\n",
    "change_daily_max = percentage_change(parameter, values[27][0], values[27][1], values[27][2], 'Max', hist_end, hist_st, yr_end, yr_st)  \n",
    "\n",
    "#Change in return period\n",
    "# Annual Max - for historical period\n",
    "filename_hist_annual_max = get_file(parameter,values[27][0],'historical',values[27][2],'Annual_Max',hist_end,hist_st)\n",
    "ds_hist_annual_max = xr.open_dataset(os.path.join(dir_in,filename_hist_annual_max))\n",
    "# Annual Max - for scenario period\n",
    "filename_scenario_annual_max = get_file(parameter,values[27][0],values[27][1],values[27][2],'Annual_Max',yr_end,yr_st)\n",
    "ds_scenario_annual_max = xr.open_dataset(os.path.join(dir_in,filename_scenario_annual_max))  \n",
    "# calculate retrun period for the historical period\n",
    "all_yT = []\n",
    "for i in range (0, len(grid_cells)): \n",
    "    hist_yT_point = gev_return_period(ts_data(ds_hist_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)\n",
    "    scenario_yT_point = gev_return_period(ts_data(ds_scenario_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)       \n",
    "    yT_point = {'hist_yT':hist_yT_point,'future_yT':scenario_yT_point}\n",
    "    all_yT.append(yT_point)\n",
    "all_return_period = pd.DataFrame(all_yT)   \n",
    "change_return_period = ((all_return_period['future_yT'].mean()-all_return_period['hist_yT'].mean())*100)/all_return_period['hist_yT'].mean()   \n",
    "dd = {'GCM':values[27][0],'Bias Correction':values[27][2],'Emission':values[27][1],'Change in Daily Mean':change_daily_mean,'Change in daily Max':change_daily_max, 'Change in Return Period':change_return_period}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GCM': 'NOAA-GFDL-GFDL-ESM2M',\n",
       " 'Bias Correction': 'r240x120-QME-AWAP',\n",
       " 'Emission': 'rcp45',\n",
       " 'Change in Daily Mean': -17.068917532352838,\n",
       " 'Change in daily Max': -3.203780330827212,\n",
       " 'Change in Return Period': -2.309028651144917}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hist_yT</th>\n",
       "      <th>future_yT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18122</th>\n",
       "      <td>66.939304</td>\n",
       "      <td>56.862671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18123</th>\n",
       "      <td>69.320159</td>\n",
       "      <td>58.651668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18124</th>\n",
       "      <td>66.322657</td>\n",
       "      <td>56.476517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18125</th>\n",
       "      <td>66.107530</td>\n",
       "      <td>56.299584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18126</th>\n",
       "      <td>66.129020</td>\n",
       "      <td>56.244852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         hist_yT  future_yT\n",
       "0            NaN        NaN\n",
       "1            NaN        NaN\n",
       "2            NaN        NaN\n",
       "3            NaN        NaN\n",
       "4            NaN        NaN\n",
       "...          ...        ...\n",
       "18122  66.939304  56.862671\n",
       "18123  69.320159  58.651668\n",
       "18124  66.322657  56.476517\n",
       "18125  66.107530  56.299584\n",
       "18126  66.129020  56.244852\n",
       "\n",
       "[18127 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_return_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.12902016388372"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_yT_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.47752452972815"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_return_period['future_yT'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.269839489960866"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_return_period['hist_yT'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = ds_hist_annual_max.sel(lat = -32.25, lon = 145.65, method = 'nearest')[parameter].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 46.3819854 ,  26.94592103,  28.9420981 ,  46.3819854 ,\n",
       "        27.72732647,  26.94592103,  18.84902897,  36.901809  ,\n",
       "        43.18356682,  77.58088075,  32.91497687,  62.61413936,\n",
       "        29.78134621,  35.35311492,  25.81488965,  14.99467702,\n",
       "        44.43557672,  35.86198362,  26.56351766, 110.88779122,\n",
       "        46.3819854 ,  19.95832315,  53.5068512 ,  40.78430654,\n",
       "        31.08606404,  24.0342943 ,  28.53136556,  40.20562079,\n",
       "        37.97175642,  41.37131805])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.93930365936576"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gev_return_period(data_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caluster_flood_indicator=[]\n",
    "for val in enumerate(values):   \n",
    "#for val in enumerate(values[0]):  \n",
    "    #Change in mean\n",
    "    change_daily_mean = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Mean', hist_end, hist_st, yr_end, yr_st)\n",
    "\n",
    "    #Change in max\n",
    "    change_daily_max = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Max', hist_end, hist_st, yr_end, yr_st)  \n",
    "    \n",
    "    #Change in return period\n",
    "    # Annual Max - for historical period\n",
    "    filename_hist_annual_max = get_file(parameter,val[1][0],'historical',val[1][2],'Annual_Max',hist_end,hist_st)\n",
    "    ds_hist_annual_max = xr.open_dataset(os.path.join(dir_in,filename_hist_annual_max))\n",
    "    # Annual Max - for scenario period\n",
    "    filename_scenario_annual_max = get_file(parameter,val[1][0],val[1][1],val[1][2],'Annual_Max',yr_end,yr_st)\n",
    "    ds_scenario_annual_max = xr.open_dataset(os.path.join(dir_in,filename_scenario_annual_max))  \n",
    "    # calculate retrun period for the historical period\n",
    "    all_yT = []\n",
    "    for i in range (0, len(grid_cells)): \n",
    "        hist_yT_point = gev_return_period(ts_data(ds_hist_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)\n",
    "        scenario_yT_point = gev_return_period(ts_data(ds_scenario_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)       \n",
    "        yT_point = {'hist_yT':hist_yT_point,'future_yT':scenario_yT_point}\n",
    "        all_yT.append(yT_point)\n",
    "    all_return_period = pd.DataFrame(all_yT)   \n",
    "    change_return_period = ((all_return_period['future_yT'].mean()-all_return_period['hist_yT'].mean())*100)/all_return_period['hist_yT'].mean()   \n",
    "    dd = {'GCM':val[1][0],'Bias Correction':val[1][2],'Emission':val[1][1],'Change in Daily Mean':change_daily_mean,'Change in daily Max':change_daily_max, 'Change in Return Period':change_return_period}\n",
    "    cluster_flood_indicator.append(dd)\n",
    "    break # just want to check one loop/one ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flood_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values[10][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flood_indicator=[]\n",
    "for val in enumerate(values):   \n",
    "#for val in enumerate(values[0]):  \n",
    "    #Change in mean\n",
    "    change_daily_mean = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Mean', hist_end, hist_st, yr_end, yr_st)\n",
    "\n",
    "    #Change in max\n",
    "    change_daily_max = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Max', hist_end, hist_st, yr_end, yr_st)  \n",
    "    \n",
    "    #Change in return period\n",
    "    # Annual Max - for historical period\n",
    "    filename_hist_annual_max = get_file(parameter,val[1][0],'historical',val[1][2],'Annual_Max',hist_end,hist_st)\n",
    "    ds_hist_annual_max = xr.open_dataset(os.path.join(dir_in,filename_hist_annual_max))\n",
    "    # calculate retrun period for the historical period\n",
    "    hist_yT = []\n",
    "    for i in range (0, len(grid_cells)): \n",
    "        hist_yT_point = gev_return_period(ts_data(ds_hist_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)\n",
    "        hist_yT.append(hist_yT_point)\n",
    "    hist_yT_mean = pd.DataFrame(hist_yT).mean()[0]\n",
    "    # Annual Max - for scenario period\n",
    "    filename_scenario_annual_max = get_file(parameter,val[1][0],val[1][1],val[1][2],'Annual_Max',yr_end,yr_st)\n",
    "    ds_scenario_annual_max = xr.open_dataset(os.path.join(dir_in,filename_scenario_annual_max))\n",
    "    # calculate retrun period for the scenario period\n",
    "    scenario_yT = []\n",
    "    for j in range (0, len(grid_cells)): \n",
    "        scenario_yT_point = gev_return_period(ts_data(ds_scenario_annual_max, grid_cells.lat[j], grid_cells.lon[j], parameter), yT)\n",
    "        scenario_yT.append(scenario_yT_point)\n",
    "    scenario_yT_mean = pd.DataFrame(scenario_yT).mean()[0]\n",
    "    change_return_period = ((scenario_yT_mean-hist_yT_mean)*100)/hist_yT_mean\n",
    "    \n",
    "    dd = {'GCM':val[1][0],'Bias Correction':val[1][2],'Emission':val[1][1],'Change in Daily Mean':change_daily_mean,'Change in daily Max':change_daily_max, 'Change in Return Period':change_return_period}\n",
    "    cluster_flood_indicator.append(dd)\n",
    "    break # just want to check one loop/one ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flood_indicator=[]\n",
    "for val in enumerate(values):   \n",
    "#for val in enumerate(values[0]):  \n",
    "    #Change in mean\n",
    "    change_daily_mean = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Mean', hist_end, hist_st, yr_end, yr_st)\n",
    "\n",
    "    #Change in max\n",
    "    change_daily_max = percentage_change(parameter, val[1][0], val[1][1], val[1][2], 'Max', hist_end, hist_st, yr_end, yr_st)  \n",
    "    \n",
    "    #Change in return period\n",
    "    # Annual Max - for historical period\n",
    "    filename_hist_annual_max = get_file(parameter,val[1][0],'historical',val[1][2],'Annual_Max',hist_end,hist_st)\n",
    "    ds_hist_annual_max = xr.open_dataset(os.path.join(dir_in,filename_hist_annual_max))\n",
    "    # Annual Max - for scenario period\n",
    "    filename_scenario_annual_max = get_file(parameter,val[1][0],val[1][1],val[1][2],'Annual_Max',yr_end,yr_st)\n",
    "    ds_scenario_annual_max = xr.open_dataset(os.path.join(dir_in,filename_scenario_annual_max))  \n",
    "    # calculate retrun period for the historical period\n",
    "    change_yT = []\n",
    "    for i in range (0, len(grid_cells)): \n",
    "        hist_yT_point = gev_return_period(ts_data(ds_hist_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)\n",
    "        scenario_yT_point = gev_return_period(ts_data(ds_scenario_annual_max, grid_cells.lat[i], grid_cells.lon[i], parameter), yT)\n",
    "        diff_yT = ((scenario_yT_point-hist_yT_point)*100)/hist_yT_point\n",
    "        change_yT.append(diff_yT)\n",
    "    change_return_period = pd.DataFrame(change_yT).mean()[0]   \n",
    "    dd = {'GCM':val[1][0],'Bias Correction':val[1][2],'Emission':val[1][1],'Change in Daily Mean':change_daily_mean,'Change in daily Max':change_daily_max, 'Change in Return Period':change_return_period}\n",
    "    cluster_flood_indicator.append(dd)\n",
    "    break # just want to check one loop/one ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_flood_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
