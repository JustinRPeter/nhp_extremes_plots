{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awrams.utils.processing.extract import extract\n",
    "from awrams.utils.gis import ShapefileDB,extent_from_record\n",
    "from awrams.utils.extents import get_default_extent\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import product\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "var_name = 'rain_day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output folder path\n",
    "customer_dir = '/g/data/er4/zk6340/Hydro_projection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set the customer folder and shapefile name\n",
    "shp_name = 'New England Combined'\n",
    "#shp_name = 'Burdekin'\n",
    "#shp_name = 'Cairns Catchment'\n",
    "# shp_name = 'Central West River Catchment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Request dir folder path\n",
    "#DataRequest_dir = '/g/data/er4/zk6340/Hydro_projection/%s/'%(shp_name)\n",
    "DataRequest_dir = '/g/data/er4/zk6340/Hydro_projection/%s/'%(shp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlbersArea</th>\n",
       "      <th>AttrRel</th>\n",
       "      <th>AttrSource</th>\n",
       "      <th>Division</th>\n",
       "      <th>FSource</th>\n",
       "      <th>FeatRel</th>\n",
       "      <th>HydroID</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>PlanAcc</th>\n",
       "      <th>RivRegName</th>\n",
       "      <th>RivRegNum</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>SrcFCName</th>\n",
       "      <th>SrcFType</th>\n",
       "      <th>SrcType</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>TextNote</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.937612e+10</td>\n",
       "      <td>2019/08/21</td>\n",
       "      <td>Bureau of Meteorology</td>\n",
       "      <td>Murray-Darling Basin</td>\n",
       "      <td>Bureau of Meteorology</td>\n",
       "      <td>2019/08/21</td>\n",
       "      <td>43637150</td>\n",
       "      <td>238</td>\n",
       "      <td>15</td>\n",
       "      <td>Combined</td>\n",
       "      <td>20</td>\n",
       "      <td>3.712643</td>\n",
       "      <td>16.507778</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>New England Combined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AlbersArea     AttrRel             AttrSource              Division  \\\n",
       "0  3.937612e+10  2019/08/21  Bureau of Meteorology  Murray-Darling Basin   \n",
       "\n",
       "                 FSource     FeatRel   HydroID  OBJECTID  PlanAcc RivRegName  \\\n",
       "0  Bureau of Meteorology  2019/08/21  43637150       238       15   Combined   \n",
       "\n",
       "  RivRegNum  Shape_Area  Shape_Leng  SourceID SrcFCName SrcFType  SrcType  \\\n",
       "0        20    3.712643   16.507778         0      None     None        0   \n",
       "\n",
       "   Symbol TextNote                  name  \n",
       "0       0     None  New England Combined  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read shape file\n",
    "shp = DataRequest_dir + shp_name + '.shp'\n",
    "sdb = ShapefileDB(shp)\n",
    "sdf = sdb.get_records_df()\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlbersArea</th>\n",
       "      <th>AttrRel</th>\n",
       "      <th>AttrSource</th>\n",
       "      <th>Division</th>\n",
       "      <th>FSource</th>\n",
       "      <th>FeatRel</th>\n",
       "      <th>HydroID</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>PlanAcc</th>\n",
       "      <th>RivRegName</th>\n",
       "      <th>RivRegNum</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>SrcFCName</th>\n",
       "      <th>SrcFType</th>\n",
       "      <th>SrcType</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>TextNote</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.937612e+10</td>\n",
       "      <td>2019/08/21</td>\n",
       "      <td>Bureau of Meteorology</td>\n",
       "      <td>Murray-Darling Basin</td>\n",
       "      <td>Bureau of Meteorology</td>\n",
       "      <td>2019/08/21</td>\n",
       "      <td>43637150</td>\n",
       "      <td>238</td>\n",
       "      <td>15</td>\n",
       "      <td>Combined</td>\n",
       "      <td>20</td>\n",
       "      <td>3.712643</td>\n",
       "      <td>16.507778</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>New England Combined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AlbersArea     AttrRel             AttrSource              Division  \\\n",
       "0  3.937612e+10  2019/08/21  Bureau of Meteorology  Murray-Darling Basin   \n",
       "\n",
       "                 FSource     FeatRel   HydroID  OBJECTID  PlanAcc RivRegName  \\\n",
       "0  Bureau of Meteorology  2019/08/21  43637150       238       15   Combined   \n",
       "\n",
       "  RivRegNum  Shape_Area  Shape_Leng  SourceID SrcFCName SrcFType  SrcType  \\\n",
       "0        20    3.712643   16.507778         0      None     None        0   \n",
       "\n",
       "   Symbol TextNote                  name  \n",
       "0       0     None  New England Combined  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read shape file\n",
    "shp = DataRequest_dir + shp_name + '.shp'\n",
    "sdb = ShapefileDB(shp)\n",
    "sdf = sdb.get_records_df()\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the extents from above the shape file - only needed if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dealing with 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'Transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-241857f723a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dealing with {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#    try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0memap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextent_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#     except Exception as err:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#         print('Error in delineation')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/er4/AWRACMS/awrams_cm_v6.1/utils/awrams/utils/gis.py\u001b[0m in \u001b[0;36mextent_from_record\u001b[0;34m(record, parent_extent, compute_areas)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_extent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_by_boundary_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_bounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msh_bounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msh_bounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msh_bounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mareas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_intersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_localise_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mll_geo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompute_areas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mareas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/er4/AWRACMS/awrams_cm_v6.1/utils/awrams/utils/gis.py\u001b[0m in \u001b[0;36mcalc_intersection\u001b[0;34m(bounds, geometry, compute_areas)\u001b[0m\n\u001b[1;32m     89\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                             \u001b[0misect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_geom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                             \u001b[0misect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LONGLAT_TO_AEA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                             \u001b[0mareas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlcell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlcell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArea\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Transform'"
     ]
    }
   ],
   "source": [
    "#Create the extents and save as pkl file if pkl is not available\n",
    "edef = get_default_extent()\n",
    "emap = {}\n",
    "for i,e in enumerate(sdf['name']): \n",
    "    print('Dealing with {}'.format(i))\n",
    "    try:\n",
    "        emap[e] = extent_from_record(sdb.records[i],edef)\n",
    "#     except Exception as err:\n",
    "#         print('Error in delineation')\n",
    "pickle.dump(emap, open(DataRequest_dir + shp_name + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<osgeo.ogr.Feature; proxy of <Swig Object of type 'OGRFeatureShadow *' at 0x7f8ed5543690> >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdb.records[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdb.records[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source the existing extents file for the above shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emap = pickle.load(open(DataRequest_dir + shp_name + '.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### period to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = {'hist':['1985-01-01 12:00:00','2005-12-31 12:00:00']}\n",
    "#period = {'scn1':['2031-01-01 12:00:00','2050-12-31 12:00:00'],'scn2':['2051-01-01 12:00:00','2070-12-31 12:00:00']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participating GCMs, Bias correction approaches, Emission scenarios\n",
    "gcms = ['CNRM-CERFACS-CNRM-CM5','CSIRO-BOM-ACCESS1-0','MIROC-MIROC5','NOAA-GFDL-GFDL-ESM2M']\n",
    "bias_corr = ['CSIRO-CCAM-r3355-r240x120-ISIMIP2b-AWAP','r240x120-ISIMIP2b-AWAP', 'r240x120-MRNBC-AWAP', 'r240x120-QME-AWAP']\n",
    "emission = ['historical']\n",
    "#emission = ['rcp45','rcp85']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all the emsemble identities\n",
    "values = [(i, k, x) for i, k, x in product(gcms, emission, bias_corr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get to the path \n",
    "def get_path(parameter,which_gcm,which_emission,which_bias_corr):\n",
    "    if parameter == 'qtot':\n",
    "        path = os.path.join('/g/data/wj02/COMPLIANT/HMOUTPUT/output/AUS-5/BoM/AWRALv6-1-%s/%s/r1i1p1/%s/latest/day/%s/'%(which_gcm,which_emission,which_bias_corr,parameter))\n",
    "    else:\n",
    "        path = os.path.join('/g/data/wj02/COMPLIANT/HMINPUT/output/AUS-5/BoM/%s/%s/r1i1p1/%s/latest/day/%s/'%(which_gcm,which_emission,which_bias_corr,parameter))\n",
    "    return(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical period\n",
    "period_hist = pd.date_range('1 jan 1976', '31 dec 2005', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to historical data\n",
    "if parameter == 'qtot':\n",
    "    data_hist = '/g/data/er4/exv563/hydro_projections/data/drought_2018_analysis/awra_v6_static_winds/daily'\n",
    "else:\n",
    "    data_hist = '/g/data/er4/data/CLIMATE/rain_day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_produced = []\n",
    "for val in enumerate(values): \n",
    "    which_catchment = val[1][0]\n",
    "    print(which_catchment)\n",
    "#         period_projected = pd.date_range(future_period[val[1][1]][0], future_period[val[1][1]][1], freq='D')\n",
    "    catchment = {}\n",
    "    for key in emap:\n",
    "        if which_catchment in key:\n",
    "            catchment[key] = emap[key]\n",
    "    #Annual max for historical data                \n",
    "    pattern = data_hist + '/%s*.nc' % var_name\n",
    "    ds_hist = extract(data_hist, pattern, var_name, catchment, period_hist)\n",
    "    data_mean_hist = ds_hist[which_catchment].values.mean()\n",
    "    data_max_hist = ds_hist[which_catchment].values.max()\n",
    "    data_annual_max_hist = ds_hist.resample(rule='A-DEC').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the calculation done!\n",
    "ensb_together = []\n",
    "for ensb in enumerate(ensb_mem):\n",
    "    ds_produced = []\n",
    "    for val in enumerate(values): \n",
    "        which_catchment = val[1][0]\n",
    "        print(which_catchment)\n",
    "#         period_projected = pd.date_range(future_period[val[1][1]][0], future_period[val[1][1]][1], freq='D')\n",
    "        catchment = {}\n",
    "        for key in emap:\n",
    "            if which_catchment in key:\n",
    "                catchment[key] = emap[key]\n",
    "        #Annual max for historical data                \n",
    "        pattern = data_hist + '/%s*.nc' % var_name\n",
    "        ds_hist = extract(data_hist, pattern, var_name, catchment, period_hist)\n",
    "        data_mean_hist = ds_hist[which_catchment].values.mean()\n",
    "        data_max_hist = ds_hist[which_catchment].values.max()\n",
    "        data_annual_max_hist = ds_hist.resample(rule='A-DEC').max()\n",
    "        \n",
    "#         #Annual max for future data    \n",
    "#         input_path_gcm = get_path(variable,ensb[1][0],ensb[1][1],ensb[1][2])\n",
    "#         input_file = get_file(ensb[1][0],ensb[1][2],ensb[1][1],variable) \n",
    "#         pattern_gcm = input_path_gcm + '/' + input_file\n",
    "#         ds_gcm = extract(input_path_gcm, pattern_gcm, variable, catchment, period_projected)\n",
    "#         if var_name == 'rain_day':\n",
    "#             ds_convrt = ds_gcm*86400\n",
    "#         else:\n",
    "#             ds_convrt = ds_gcm\n",
    "#         data_mean_future = ds_convrt[which_catchment].values.mean()\n",
    "#         data_max_future = ds_convrt[which_catchment].values.max()\n",
    "#         data_annual_max_future = ds_convrt.resample(rule='A-DEC').max()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in enumerate(values):    \n",
    "        for key, value in period.items():\n",
    "                    print(val[1])\n",
    "                    v = parameter\n",
    "                    input_path = get_path(parameter,val[1][0],val[1][1],val[1][2])\n",
    "                    pattern = input_path + '*%s*.nc' % v                    \n",
    "                    extraction_period = pd.date_range(value[0], value[1], freq='D')\n",
    "                    print('input file path:', pattern)   \n",
    "                    ddf = extract(input_path, pattern, v, emap, extraction_period)\n",
    "                    # save daily/monthly/annual data in mm\n",
    "                    print('writing data for', v)\n",
    "                    dir_name = customer_dir+'%s_VIC_%s_%s'%(v,val[1][1],extraction_period[-1].strftime('%Y%m%d'))\n",
    "                    os.makedirs(dir_name, exist_ok=True)\n",
    "                    filename_daily = '%s_%s_%s_%s_daily.csv'%(v,shp_name,val[1][2],val[1][0])\n",
    "                    filename_monthly = '%s_%s_%s_%s_monthly.csv'%(v,shp_name,val[1][2],val[1][0])\n",
    "                    filename_annual = '%s_%s_%s_%s_annual.csv'%(v,shp_name,val[1][2],val[1][0])\n",
    "                    ddf.to_csv((os.path.join(dir_name,filename_daily)), index=True)  \n",
    "                    ddf.resample('MS').sum().to_csv((os.path.join(dir_name,filename_monthly)), index=True) \n",
    "                    ddf.resample(rule='A-DEC').sum().to_csv((os.path.join(dir_name,filename_annual)), index=True) \n",
    "                    break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (ddf.isnull().all() == False):\n",
    "    print ('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
